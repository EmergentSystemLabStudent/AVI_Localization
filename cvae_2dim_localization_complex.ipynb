{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j67_JrYGWZUo"
   },
   "source": [
    "# Conditional variational autoencoder (using the VAE class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLUiwGU7T1vi"
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3817,
     "status": "ok",
     "timestamp": 1550233916848,
     "user": {
      "displayName": "福井隆士",
      "photoUrl": "",
      "userId": "02045005220596599994"
     },
     "user_tz": -540
    },
    "id": "TBHblcMRZKn9",
    "outputId": "5ad519d8-c03f-4796-f642-9a4a272c934c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4595,
     "status": "ok",
     "timestamp": 1550233917664,
     "user": {
      "displayName": "福井隆士",
      "photoUrl": "",
      "userId": "02045005220596599994"
     },
     "user_tz": -540
    },
    "id": "45bRD1cpWfHf",
    "outputId": "3a663093-b755-4bfe-b6b6-4eddab20fe8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'pixyz'...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git clone https://github.com/masa-su/pixyz.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7062,
     "status": "ok",
     "timestamp": 1550233920152,
     "user": {
      "displayName": "福井隆士",
      "photoUrl": "",
      "userId": "02045005220596599994"
     },
     "user_tz": -540
    },
    "id": "I61Op0VnnTqU",
    "outputId": "a183afd0-05b1-4937-d55f-9acd69c40b1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 19.0.2 from /usr/local/lib/python3.6/dist-packages/pip (python 3.6)\n"
     ]
    }
   ],
   "source": [
    "!pip --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4rDmVwWccb7"
   },
   "outputs": [],
   "source": [
    "# !apt-get update && apt-get install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nmZwgIqWWhCL"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch\n",
    "!pip install tensorboardX\n",
    "!pip install -e pixyz\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1jSHxt1MT9_O"
   },
   "source": [
    "# CVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0Xp3qiUULlT"
   },
   "source": [
    "generative process\n",
    "\n",
    "3dimention data\n",
    "\n",
    "position(x,y,θ)\n",
    "\n",
    "c=f(ut,s(t-1))\n",
    "\n",
    "st~p(st|ut, s(t-1))=N(c , sigma)\n",
    "\n",
    "ot=N(h(st),sigma)\n",
    "\n",
    "hは計測モデル，\n",
    "ランドマークは(xc,yc,c)で構成，\n",
    "hにより相対位置に変換される，\n",
    "具体的には(距離と角度)\n",
    "\n",
    "\n",
    "それぞれの分散共分散行列には対角行列を使用（制御がめんどそうだから"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HTEX8JBTWZU0"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 128\n",
    "epochs =200#10\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0NnqgDqeWZVG"
   },
   "outputs": [],
   "source": [
    "root = '../data'\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Lambda(lambd=lambda o: o.view(-1))])\n",
    "kwargs = {'batch_size': batch_size, 'num_workers': 1, 'pin_memory': True}\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST(root=root, train=True, transform=transform, download=True),\n",
    "#     shuffle=True, **kwargs)\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST(root=root, train=False, transform=transform),\n",
    "#     shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nd8GW4-lCu6k"
   },
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25192,
     "status": "error",
     "timestamp": 1550233938404,
     "user": {
      "displayName": "福井隆士",
      "photoUrl": "",
      "userId": "02045005220596599994"
     },
     "user_tz": -540
    },
    "id": "WhrtlAchWZVV",
    "outputId": "446e429c-9b6b-432a-d8c8-c8fe4f935899"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9f5d32beb7fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpixyz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBernoulli\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpixyz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKullbackLeibler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpixyz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pixyz.distributions'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pixyz.distributions import Normal, Bernoulli\n",
    "from pixyz.losses import KullbackLeibler\n",
    "from pixyz.models import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q421y_YjKWLO"
   },
   "outputs": [],
   "source": [
    "#function for generate data\n",
    "import torch.distributions as dist\n",
    "\n",
    "def unif_landgenerator(sample_num):\n",
    "  #range is [-180:180]\n",
    "  sample_axis=torch.FloatTensor(sample_num,2).uniform_(0,100)\n",
    "  sample_theta=torch.FloatTensor(sample_num).uniform_(-np.pi,np.pi)\n",
    "  landmark=torch.cat([sample_axis,sample_theta.view(sample_num,1)],dim=1)\n",
    "  return landmark\n",
    "\n",
    "def get_h(st,lmap):\n",
    "  #まずstから各lcまでの距離を計算して行列にいれとく\n",
    "#   dis=torch.Tensor(len(lmap),len(st))\n",
    "  disangle={}\n",
    "  dis=torch.stack([torch.sqrt((st[:,0]-lmap[i][0])**2+(st[:,1]-lmap[i][1])**2)\\\n",
    "                   for i in range(len(lmap))],dim=0)\n",
    "  angle=torch.stack([torch.atan2((lmap[i][0]-st[:,0]),(lmap[i][1]-st[:,1]))-st[:,2]\\\n",
    "                     for i in range(len(lmap))],dim=0)\n",
    "  disangle.update({\"dis\":dis,\"angle\":angle})\n",
    "  return disangle\n",
    "\n",
    "#st*lmap*2  \n",
    "def get_ot(st,lmap,r):#(robot_pos, map(landmarks), measurement_range)\n",
    "  print(len(st),len(lmap))\n",
    "  disangle=get_h(st,lmap)\n",
    "  ot=torch.ones(len(st),len(lmap),2)*100.0\n",
    "  for i in range(len(st)):\n",
    "    for j in range(len(lmap)):\n",
    "      if disangle[\"dis\"][j][i]<=r:\n",
    "        ot[i][j][0]=disangle[\"dis\"][j][i]\n",
    "        ot[i][j][1]=disangle[\"angle\"][j][i]\n",
    "  return ot#[sample_num*lmap_num*2[dis,angle]]\n",
    "      \n",
    "def inverse_ot_fast(st,ot,r):#inverse_otの処理を高速化した\n",
    "  lnx=[]\n",
    "  lny=[]\n",
    "  bias=10.0\n",
    "  for j in range(len(ot[0])):#landmark数\n",
    "      lx=st[:,0]+torch.sin(ot[:,j,1]/bias+st[:,2]/bias)*ot[:,j,0]\n",
    "      ly=st[:,1]+torch.cos(ot[:,j,1]/bias+st[:,2]/bias)*ot[:,j,0]\n",
    "      lnx.append(lx)\n",
    "      lny.append(ly)\n",
    "  lnx=torch.stack(lnx,dim=1)#30000*20\n",
    "  lny=torch.stack(lny,dim=1)\n",
    "  ot2=ot[:,:,0]\n",
    "  lx=lnx[ot2<=r]\n",
    "  ly=lny[ot2<=r]\n",
    "  \n",
    "  return torch.stack([lx,ly],dim=1)\n",
    "\n",
    "#st(x,y,theta),ot(dis,angle),r(range)->landmark_axis(x,y)\n",
    "def inverse_ot(st,ot,r):\n",
    "  ln=[]\n",
    "  for i in range(len(st)):#sample数\n",
    "    for j in range(len(ot[0])):#landmark数\n",
    "      if ot[i][j][0]<=r:\n",
    "        lx=st[i][0]+torch.sin(ot[i][j][1]/10.0+st[i][2]/10.0)*ot[i][j][0]\n",
    "        ly=st[i][1]+torch.cos(ot[i][j][1]/10.0+st[i][2]/10.0)*ot[i][j][0]\n",
    "        ln.append(torch.stack([lx,ly],dim=0))\n",
    "#     if len(ln)==0:return ln\n",
    "  return torch.stack(ln,dim=0)\n",
    "      \n",
    "  \n",
    "#   return lc#lcはstごとのランドマーク行列\n",
    "# def transform_randmark(st,lc,lmap):\n",
    "#   st[:,0]\n",
    "\n",
    "def origin_datagenerator(sample_num,dsigma,axis):\n",
    "  data_cso={}\n",
    "  \n",
    "  ones=torch.ones(int(sample_num/3))\n",
    "  \n",
    "  sample_ca = torch.stack([ones*axis[0][0],ones*axis[0][1],ones*axis[0][2]],1)\n",
    "  sample_cb = torch.stack([ones*axis[1][0],ones*axis[1][1],ones*axis[1][2]],1)\n",
    "  sample_cc = torch.stack([ones*axis[2][0],ones*axis[2][1],ones*axis[2][2]],1)\n",
    "  data_cso.update({\"c\":torch.cat([sample_ca,sample_cb,sample_cc],dim=0)})\n",
    "  data_cso.update({\"s\":dist.Normal(data_cso[\"c\"],dsigma).sample()})\n",
    "  data_cso.update({\"o\":dist.Normal(data_cso[\"s\"],dsigma).sample()})\n",
    "#   data_cso.update([ (\"c\",torch.cat([sample_ca,sample_cb,sample_cc],dim=0)), (\"s\",dist.Normal(data_cso[\"c\"],dsigma).sample()) ])\n",
    "  \n",
    "  return data_cso\n",
    "  \n",
    "#dataset sampling from Uniform[0:100]\n",
    "def unique_datagenerator(sample_num,dsigma):\n",
    "  data_cso={}\n",
    "  \n",
    "  sample_c1=torch.rand(sample_num)*100#一様分布からの場合\n",
    "  sample_c2=torch.rand(sample_num)*100\n",
    "  sample_theta=torch.FloatTensor(sample_num).uniform_(-np.pi,np.pi)\n",
    "  data_cso.update({\"c\":torch.cat([sample_c1.view(sample_num,1),sample_c2.view(sample_num,1),sample_theta.view(sample_num,1)],dim=1)})\n",
    "  data_cso.update({\"s\":dist.Normal(data_cso[\"c\"],dsigma).sample()})\n",
    "  return data_cso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5L3Qm7ePucd"
   },
   "outputs": [],
   "source": [
    "sample_num=6000\n",
    "landmark_num=20\n",
    "range_of_measure=200\n",
    "dsigma=torch.Tensor([0.3,0.3,0.3]*sample_num).view(sample_num,3)\n",
    "axis=[[30,9,0.5],[40,90,-1.4],[72,60,-3.0]]\n",
    "\n",
    "max_data=100.0\n",
    "min_data=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nUx0idupYqOo"
   },
   "outputs": [],
   "source": [
    "# #data generate\n",
    "# lmap=unif_landgenerator(landmark_num)\n",
    "# data=unique_datagenerator(sample_num,dsigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sC_pQ8AzIEqr"
   },
   "outputs": [],
   "source": [
    "#data generate\n",
    "\n",
    "#generate landmark,condition,true_st\n",
    "lmap=unif_landgenerator(landmark_num)\n",
    "data=origin_datagenerator(sample_num,dsigma,axis)\n",
    "# test_data=origin_datagenerator(sample_num,dsigma,axis)\n",
    "ot=get_ot(data[\"s\"],lmap,range_of_measure)\n",
    "print(ot)\n",
    "\n",
    "#角度のdataを10倍で合わせる\n",
    "ot[:,:,1]=torch.atan2(torch.sin(ot[:,:,1]),torch.cos(ot[:,:,1]))*10\n",
    "data[\"c\"][:,2]=data[\"c\"][:,2]*10\n",
    "data[\"s\"][:,2]=torch.atan2(torch.sin(data[\"s\"][:,2]),torch.cos(data[\"s\"][:,2]))*10\n",
    "\n",
    "\n",
    "# ot=ot.view(sample_num,landmark_num*2)\n",
    "data.update({\"o\":ot.view(sample_num,landmark_num*2)})\n",
    "# print(ot.size())\n",
    "print(data[\"c\"].size())\n",
    "train = torch.utils.data.TensorDataset(data[\"o\"], data[\"c\"])\n",
    "train_loader = torch.utils.data.DataLoader(train, shuffle=False,**kwargs)\n",
    "# test = torch.utils.data.TensorDataset(test_data[\"o\"], test_data[\"c\"])\n",
    "# test_loader = torch.utils.data.DataLoader(test, shuffle=False,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpe1FywXCJQM"
   },
   "outputs": [],
   "source": [
    "# #obserbation\n",
    "# # print(get_h(data[\"c\"],lmap))\n",
    "# iot=inverse_ot_fast(data[\"s\"],ot,range_of_measure)\n",
    "# # print(iot.size())\n",
    "# plt.scatter(iot[:,0],iot[:,1],color='blue',marker='o',edgecolors=\"red\")\n",
    "plt.scatter(lmap[:,0],lmap[:,1],color='red',marker='x',edgecolors=\"red\")\n",
    "# plt.scatter(data[\"c\"][:,0],data[\"c\"][:,1],color='yellow',marker='x',edgecolors=\"red\")\n",
    "plt.xlim(min_data,max_data)\n",
    "plt.ylim(min_data,max_data)\n",
    "plt.xlabel('$sx$', fontsize=16)\n",
    "plt.ylabel('$sy$', fontsize=16)\n",
    "plt.title(\"Simulated dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iq38NAYsWZVf"
   },
   "outputs": [],
   "source": [
    "o_dim = landmark_num*2\n",
    "c_dim = 3\n",
    "s_dim = 3\n",
    "hidden=(landmark_num*2+3)\n",
    "\n",
    "\n",
    "# inference model q(z|x,y)\n",
    "class Inference(Normal):\n",
    "    def __init__(self):\n",
    "        super(Inference, self).__init__(cond_var=[\"o\",\"c\"], var=[\"s\"], name=\"q\")\n",
    "\n",
    "        self.fc1 = nn.Linear(o_dim+c_dim, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "        self.fc3 = nn.Linear(hidden, hidden)\n",
    "        self.fc31 = nn.Linear(hidden, s_dim)\n",
    "        self.fc32 = nn.Linear(hidden, s_dim)\n",
    "\n",
    "    def forward(self, o, c):\n",
    "        h = F.relu(self.fc1( torch.cat([o,c],1) ))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        h = F.relu(self.fc3(h))\n",
    "        return {\"loc\": self.fc31(h), \"scale\": F.softplus(self.fc32(h))}\n",
    "\n",
    "    \n",
    "# generative model p(x|z,y)   \n",
    "class Generator2(Normal):\n",
    "    def __init__(self):\n",
    "        super().__init__(cond_var=[\"s\"], var=[\"o\"], name=\"p\")\n",
    "\n",
    "        self.fc1 = nn.Linear(s_dim, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "        self.fc25 = nn.Linear(hidden, hidden)\n",
    "        self.fc3 = nn.Linear(hidden, o_dim)\n",
    "\n",
    "    def forward(self, s):\n",
    "#         print(s)\n",
    "#         print(s.shape)\n",
    "        h = F.relu(self.fc1(s))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        h = F.relu(self.fc25(h))\n",
    "        return {\"loc\": self.fc3(h),\"scale\":(torch.ones(o_dim)*0.3).to(device)}\n",
    "\n",
    "# prior = Normal(loc=loc, scale=scale, cond_var=[\"c\"],var=[\"s\"], dim=s_dim, name=\"p_prior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8rqB8MMxOZV"
   },
   "outputs": [],
   "source": [
    "# prior model p(z|c)\n",
    "class prior_set(Normal):\n",
    "    def forward(self, c):\n",
    "        return{\"loc\":c, \"scale\":torch.tensor([0.3,0.3,0.3]).to(device)}\n",
    "      \n",
    "prior = prior_set(cond_var=[\"c\"],var=[\"s\"], dim=s_dim, name=\"p_prior\")\n",
    "print(prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fcaT6KZRWZVo"
   },
   "outputs": [],
   "source": [
    "p = Generator2()\n",
    "q = Inference()\n",
    "\n",
    "p.to(device)\n",
    "q.to(device)\n",
    "\n",
    "print(p)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bLY4sjykWZV0"
   },
   "outputs": [],
   "source": [
    "kl = KullbackLeibler(q, prior)\n",
    "print(kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6287Mah5WZWE"
   },
   "outputs": [],
   "source": [
    "model = VAE(q, p, regularizer=kl, optimizer=optim.Adam, optimizer_params={\"lr\":1e-3})\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xK-CrDtnWZWO"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    train_loss = 0\n",
    "    for o,c in tqdm(train_loader):\n",
    "        o = o.to(device)\n",
    "        c = c.to(device)\n",
    "#         print(o.size())\n",
    "#         print(c.size())\n",
    "#         print(o)\n",
    "        loss = model.train({\"o\": o, \"c\": c})\n",
    "        train_loss += loss\n",
    "        \n",
    "#     print(kl.gauss_gauss_kl(, scale1, loc2, scale2, dim=None))\n",
    "    train_loss = train_loss * train_loader.batch_size / len(data[\"c\"])\n",
    "    print('Epoch: {} Train loss: {:.4f}'.format(epoch, train_loss))\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NtsbwstlAs4s"
   },
   "outputs": [],
   "source": [
    "# print(train_loader.batch_size)\n",
    "# print(len(train_loader))\n",
    "# print(dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j953elFiWZWf"
   },
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    test_loss = 0\n",
    "    for o, c in test_loader:\n",
    "        o = o.to(device)\n",
    "        c = c.to(device)\n",
    "        loss = model.test({\"o\": o, \"c\": c})\n",
    "        test_loss += loss\n",
    "        \n",
    "\n",
    "    test_loss = test_loss * test_loader.batch_size / len(test_data[\"c\"])\n",
    "    print('Test loss: {:.4f}'.format(test_loss))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p6gFB8sQEfWQ"
   },
   "outputs": [],
   "source": [
    "# model.test({\"o\":do[0].unsqueeze(0).to(device),\"c\":dc[0].unsqueeze(0).to(device)})\n",
    "# q.sample(\"o\":do[0],\"c\":dc[0], return_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-otzcm_eWZWs"
   },
   "outputs": [],
   "source": [
    "def plot_reconstrunction(o, c):\n",
    "    with torch.no_grad():\n",
    "        s = q.sample({\"o\": o, \"c\": c}, return_all=False)\n",
    "        s.update({\"c\": c})\n",
    "        recon_batch = p.sample_mean(s).view(-1, 1, 28, 28)\n",
    "    \n",
    "        recon = torch.cat([o.view(-1, 1, 28, 28), recon_batch]).cpu()\n",
    "        return recon\n",
    "    \n",
    "def plot_image_from_latent(s, c):\n",
    "    with torch.no_grad():\n",
    "        sample = p.sample_mean({\"s\": s, \"c\": c}).view(-1, 1, 28, 28).cpu()\n",
    "        return sample\n",
    "    \n",
    "def plot_reconstrunction_changing_y(o, c):\n",
    "    c_change = torch.eye(10)[range(7)].to(device)\n",
    "    batch_dummy = torch.ones(o.size(0))[:, None].to(device)    \n",
    "    recon_all = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _c in c_change:\n",
    "            s = q.sample({\"o\": o, \"c\": c}, return_all=False)\n",
    "            s.update({\"c\": batch_dummy * _c[None,:]})\n",
    "            recon_batch = p.sample_mean(s).view(-1, 1, 28, 28)\n",
    "            recon_all.append(recon_batch)\n",
    "    \n",
    "        recon_changing_c = torch.cat(recon_all)\n",
    "        recon_changing_c = torch.cat([o.view(-1, 1, 28, 28), recon_changing_c]).cpu()\n",
    "        return recon_changing_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s6s9BnZPTCWQ"
   },
   "outputs": [],
   "source": [
    "#prepare for plot\n",
    "history = {\"train_loss\":[],\"test_loss\":[]}\n",
    "\n",
    "ims=[]#animation variable\n",
    "# sample_s=dist.Normal(dc,dsigma).sample()\n",
    "# sample_o=dist.Normal(sample_s,dsigma).sample()\n",
    "\n",
    "grid_inter=10.0\n",
    "\n",
    "plt.xlim([min_data,max_data])\n",
    "plt.ylim([min_data,max_data])\n",
    "\n",
    "plt.xlabel('$sx$', fontsize=16)\n",
    "plt.ylabel('$sy$', fontsize=16)\n",
    "plt.title(\"Simulated dataset\")\n",
    "\n",
    "# plt.xticks(np.arange(-2,6,1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sT9V4ciZWZW3"
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "plot_number = 1\n",
    "\n",
    "s_sample = 0.5 * torch.randn(64, s_dim).to(device)\n",
    "c_sample = torch.eye(10)[[plot_number]*64].to(device)\n",
    "\n",
    "# _o, _c = iter(test_loader).next()\n",
    "# _o = _o.to(device)\n",
    "# _c = torch.eye(10)[_c].to(device)\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(epoch)\n",
    "#     test_loss = test(epoch)\n",
    "    \n",
    "#     recon = plot_reconstrunction(_o[:8], _c[:8])\n",
    "#     sample = plot_image_from_latent(s_sample, c_sample)\n",
    "#     recon_changing_c = plot_reconstrunction_changing_c(_o[:8], _c[:8])\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss.item(), epoch)\n",
    "#     writer.add_scalar('test_loss', test_loss.item(), epoch)\n",
    "    \n",
    "    #for plot\n",
    "    history[\"train_loss\"].append(train_loss.item())\n",
    "#     history[\"test_loss\"].append(test_loss.item())\n",
    "\n",
    "    _s = q.sample({\"o\": data[\"o\"].to(device), \"c\": data[\"c\"].to(device)}, return_all=False)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    tru = plt.scatter(data[\"s\"][:,0],data[\"s\"][:,1],color='blue',marker='o',edgecolors=\"blue\")\n",
    "    plt.xticks(np.arange(min_data,max_data+20,grid_inter))\n",
    "    plt.yticks(np.arange(min_data,max_data+20,grid_inter))\n",
    "    plt.ylabel('$sy$', fontsize=16)\n",
    "    plt.xlabel('$sx$', fontsize=16)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    sam = plt.scatter(_s[\"s\"][:,0].cpu(),_s[\"s\"][:,1].cpu(),color='red',marker='x',edgecolors=\"red\")\n",
    "    plt.xticks(np.arange(min_data,max_data+20,grid_inter))\n",
    "    plt.yticks(np.arange(min_data,max_data+20,grid_inter))\n",
    "    plt.xlabel('$sx$', fontsize=16)\n",
    "    ims.append([tru]+[sam])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "#     writer.add_image('Image_from_latent', sample, epoch)\n",
    "#     writer.add_image('Image_reconstrunction', recon, epoch)\n",
    "#     writer.add_image('Image_reconstrunction_change_c', recon_changing_c, epoch)\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hGz-7pxkS7XH"
   },
   "outputs": [],
   "source": [
    "# #animation\n",
    "# def iinit():    \n",
    "#     return (ims[0])\n",
    "# # animation function: this is called sequentially\n",
    "# def animate(i):\n",
    "#   return (ims[i])\n",
    "\n",
    "# #plot gif\n",
    "# fig = plt.figure()\n",
    "# plt.legend(['True','Result'], loc='upper left', fontsize=16)\n",
    "# ani = animation.ArtistAnimation(fig, ims)\n",
    "# anim = animation.FuncAnimation(fig, animate, init_func=iinit, frames=epochs, interval=100, blit=True)\n",
    "# plt.rcParams['animation.ffmpeg_path'] = '/usr/bin/ffmpeg' # For google colab\n",
    "# HTML(ani.to_html5_video())\n",
    "# rc('animation', html='jshtml')\n",
    "# anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QHs1D1ECgB92"
   },
   "outputs": [],
   "source": [
    "#plot loss    \n",
    "plt.ylabel('$loss$', fontsize=16)\n",
    "plt.xlabel('$epoch$', fontsize=16)\n",
    "plt.title(\"train_loss\")\n",
    "plt.plot(range(epochs), history[\"train_loss\"])\n",
    "plt.show()\n",
    "# plt.title(\"test_loss\")\n",
    "# plt.plot(range(epochs), history[\"test_loss\"])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G6LAms4uk7hG"
   },
   "outputs": [],
   "source": [
    "# sample_num=300\n",
    "\n",
    "# dsigma=torch.Tensor([0.3,0.3]*sample_num).view(sample_num,2)\n",
    "#sample dataset\n",
    "\n",
    "# ca_axis=[-3,-2]\n",
    "# cb_axis=[3,3]\n",
    "# cc_axis=[7,5]\n",
    "\n",
    "# ones=torch.ones(int(sample_num/3))\n",
    "\n",
    "# #sample dataset\n",
    "# #cを自分で定義した場合\n",
    "# sample_ca = torch.stack([ones*ca_axis[0],ones*ca_axis[1]],0)\n",
    "# sample_cb = torch.stack([ones*cb_axis[0],ones*cb_axis[1]],0)\n",
    "# sample_cc = torch.stack([ones*cc_axis[0],ones*cc_axis[1]],0)\n",
    "# sample_c=torch.cat([sample_ca,sample_cb,sample_cc],dim=1).view(sample_num,2)\n",
    "\n",
    "\n",
    "\n",
    "# sample_c=torch.rand(sample_num)*100#一様分布からの場合\n",
    "\n",
    "# sample_s=dist.Normal(sample_c,dsigma).sample()\n",
    "# sample_o=dist.Normal(sample_s,dsigma).sample()\n",
    "\n",
    "# _s = q.sample_mean({\"o\": sample_o.to(device), \"c\": sample_c.to(device)})\n",
    "# data=origin_datagenerator(sample_num,dsigma,axis)\n",
    "_s = q.sample({\"o\": data[\"o\"].to(device), \"c\": data[\"c\"].to(device)}, return_all=False)\n",
    "_o= p.sample({\"s\": _s[\"s\"].to(device)}, return_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uccCFK6-auit"
   },
   "outputs": [],
   "source": [
    "# print(_s)\n",
    "# print(_o[\"o\"])\n",
    "# print(_o[\"o\"].view(sample_num,landmark_num,2))\n",
    "# oot=ot.view(sample_num,landmark_num,2).to(device)\n",
    "_oo=_o[\"o\"].view(sample_num,landmark_num,2).cpu()\n",
    "# print(_oo.size())\n",
    "# print(_oo[0][0])\n",
    "_oo_loss=0\n",
    "ct=0\n",
    "for i in range(sample_num):\n",
    "  for j in range(landmark_num):\n",
    "    if _oo[i][j][0]<=200:\n",
    "      _oo_loss+=torch.abs(_oo[i][j]-ot[i][j])\n",
    "      ct+=1\n",
    "print(_oo_loss/ct)\n",
    "# print(data[\"s\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mErQ6u4y9mr"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# _s = q.sample({\"o\": ot.to(device), \"c\": data[\"c\"].to(device)}, return_all=False)\n",
    "# _o= p.sample({\"s\": _s[\"s\"].to(device)}, return_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b97YppxJ4IlN"
   },
   "outputs": [],
   "source": [
    "sample_num=1\n",
    "tamesi=unique_datagenerator(sample_num,torch.Tensor([0.3,0.3,0.3]*sample_num).view(sample_num,3))\n",
    "tamesi[\"s\"][:,2]=torch.atan2(torch.sin(tamesi[\"s\"][:,2]),torch.cos(tamesi[\"s\"][:,2]))\n",
    "_oo= p.sample({\"s\": tamesi[\"s\"].to(device)}, return_all=False)[\"o\"].view(sample_num,landmark_num,2)\n",
    "_oo_true=get_ot(tamesi[\"s\"],lmap,range_of_measure)\n",
    "\n",
    "np.set_printoptions(precision=5)\n",
    "print(_oo)\n",
    "print(_oo_true)\n",
    "print(tamesi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2oM95XP89nJ"
   },
   "outputs": [],
   "source": [
    "print(_s)\n",
    "print(_o[\"o\"])\n",
    "print(data[\"s\"])\n",
    "print(_oo.size())\n",
    "# _ioo=inverse_ot_fast(tamesi[\"s\"].to(device),_oo,range_of_measure)\n",
    "_ioo=inverse_ot_fast(tamesi[\"s\"].to(device),_oo.to(device),range_of_measure)\n",
    "sample_num=20000\n",
    "iot=inverse_ot_fast(data[\"s\"].to(device),ot.to(device),range_of_measure)\n",
    "\n",
    "\n",
    "# plt.scatter(tamesi[\"s\"][:,0],tamesi[\"s\"][:,1],color='yellow',marker='o',edgecolors=\"yellow\")\n",
    "# plt.scatter(sample_o[:,0],sample_o[:,1],color='blue',marker='o',edgecolors=\"blue\")\n",
    "\n",
    "plt.scatter(_ioo[:,0].cpu(),_ioo[:,1].cpu(),color='blue',marker='x',edgecolors=\"red\")\n",
    "plt.scatter(iot[:,0].cpu(),iot[:,1].cpu(),color='red',marker='x',edgecolors=\"red\")\n",
    "plt.xlabel('$sx$', fontsize=16)\n",
    "plt.ylabel('$sy$', fontsize=16)\n",
    "plt.title(\"Simulated dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o7HCeyaGVyEY"
   },
   "outputs": [],
   "source": [
    "loss=0\n",
    "_ss=_s[\"s\"].cpu()\n",
    "for i in range(0,len(data[\"s\"][i])-1,1):\n",
    "    loss+=torch.abs(data[\"s\"][i]-_ss[i])\n",
    "print(loss/sample_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V4CaNuf06i1P"
   },
   "outputs": [],
   "source": [
    "max_data=10#max_data\n",
    "min_data=-4#min_data\n",
    "grid_inter=1\n",
    "\n",
    "plot_data=test_data\n",
    "\n",
    "_s = q.sample({\"o\": plot_data[\"o\"].to(device), \"c\": plot_data[\"c\"].to(device)}, return_all=False)\n",
    "\n",
    "#show sample points\n",
    "plt.scatter(plot_data[\"s\"][:,0],plot_data[\"s\"][:,1],color='blue',marker='o',edgecolors=\"blue\")\n",
    "plt.scatter(_s[\"s\"][:,0],_s[\"s\"][:,1],color='red',marker='x',edgecolors=\"red\")\n",
    "plt.xlabel('$sx$', fontsize=16)\n",
    "plt.ylabel('$sy$', fontsize=16)\n",
    "plt.title(\"Simulated dataset\")\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(plot_data[\"s\"][:,0],plot_data[\"s\"][:,1],color='blue',marker='o',edgecolors=\"blue\")\n",
    "plt.xticks(np.arange(min_data-1,max_data+1,grid_inter))\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(_s[\"s\"][:,0],_s[\"s\"][:,1],color='red',marker='x',edgecolors=\"red\")\n",
    "plt.xticks(np.arange(min_data-1,max_data+1,grid_inter))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "xLUiwGU7T1vi"
   ],
   "name": "cvae_2dim_localization_complex.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
