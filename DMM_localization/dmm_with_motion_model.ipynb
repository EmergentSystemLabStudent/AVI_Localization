{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Markov Model with motion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b12f9e7e490>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128#128\n",
    "epochs = 100\n",
    "seed = 1\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#計測モデルとか\n",
    "def get_ot(st,lmap,max_range):\n",
    "    dis = torch.sqrt((st[:,0]-lmap[0])**2+(st[:,1]-lmap[1])**2)\n",
    "    angle = torch.atan2((lmap[1]-st[:,1]),(lmap[0]-st[:,0]))-st[:,2]\n",
    "    return torch.stack([dis,angle],1)\n",
    "    \n",
    "def get_all_ot(st,lmap,max_range):\n",
    "    measure = get_ot(st,lmap[0],max_range)\n",
    "    for l in range(1,len(lmap)):\n",
    "        measure = torch.cat([measure, get_ot(st,lmap[l],max_range)],1)\n",
    "    return torch.tensor(measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_num = 10\n",
    "start_pos = [2.0,4.0,0.0]#x0,y0,yaw0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_dim = 2\n",
    "x_dim = landmark_num*2\n",
    "h_dim = 32 #32\n",
    "hidden_dim = 32 #32\n",
    "z_dim = 3\n",
    "u_dim = 2\n",
    "t_max = 89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, *args):\n",
    "    if len(args) == 0:\n",
    "        max_data = torch.max(abs(data))\n",
    "        data=data/max_data\n",
    "    else :\n",
    "        max_data=torch.max(abs(torch.tensor(args)))\n",
    "        data=data/max_data\n",
    "    return data\n",
    "\n",
    "def normalize(data, *args):\n",
    "    if len(args) == 0:#未実装\n",
    "        max_data = torch.max(abs(data))\n",
    "        data=data/max_data\n",
    "    else :\n",
    "        max_data=torch.max(abs(torch.tensor(args)))\n",
    "        data=data*max_data\n",
    "    return data\n",
    "\n",
    "def ot_normal(ot,range_ot):\n",
    "    ot=ot.view(len(ot),10,2)\n",
    "    ot[:,:,0]=normalize(ot[:,:,0],range_ot[0][0],range_ot[0][1])\n",
    "    ot[:,:,1]=normalize(ot[:,:,1],range_ot[1][0],range_ot[1][1])\n",
    "    ot = ot.view(len(ot),20)\n",
    "    return ot\n",
    "\n",
    "def inv_ot_normal(ot,range_ot):\n",
    "    ot=ot.view(len(ot),10,2)\n",
    "    ot[:,:,0]=ot[:,:,0]*torch.max(range_ot[0][0],range_ot[0][1])\n",
    "    ot[:,:,1]=ot[:,:,1]*torch.max(range_ot[1][0],range_ot[1][1])\n",
    "    ot = ot.view(len(ot),20)\n",
    "    return ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([66, 3])\n",
      "torch.Size([1000, 66, 3])\n"
     ]
    }
   ],
   "source": [
    "#データの読み込み\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "kwargs = {'batch_size': batch_size, 'num_workers': 1, 'pin_memory': True}\n",
    "\n",
    "range_ot=torch.tensor([[0.0,150.0],[-np.pi*2,np.pi*2]])#otの[dis,theta]の最大と最小\n",
    "range_ut=torch.tensor([[0.0,5.0],[-np.pi/2.0,np.pi/2.0]])#utの[v,r]\n",
    "\n",
    "#data loader #とりあえず1時系列分を分身させて食わせてる\n",
    "#[time,s_x,s_y,s_yaw,uv,ur,ot[1],,,,ot[N]]\n",
    "data = np.loadtxt('vehicle_motion_data.csv', delimiter=',')\n",
    "data = torch.tensor([data],dtype=torch.float32)\n",
    "st = data[0,:,1:(1+z_dim)]\n",
    "ut = data[0,:,(1+z_dim):(1+z_dim+u_dim)]\n",
    "ot = data[0,:,(1+z_dim+u_dim):(1+z_dim+u_dim+x_dim)]\n",
    "t_max = len(ot)\n",
    "ot=ot_normal(ot,range_ot)\n",
    "\n",
    "ut[:,0]=normalize(ut[:,0],range_ut[0][0],range_ut[0][1])\n",
    "ut[:,1]=normalize(ut[:,1],range_ut[1][0],range_ut[1][1])\n",
    "\n",
    "print(st.size())\n",
    "st=st.repeat(1000,1,1)\n",
    "ut=ut.repeat(1000,1,1)\n",
    "ot=ot.repeat(1000,1,1)\n",
    "print(st.size())\n",
    "\n",
    "\n",
    "landmark = np.loadtxt('landmark_data.csv',delimiter=',')\n",
    "\n",
    "train = torch.utils.data.TensorDataset(ot,ut)\n",
    "train_loader = torch.utils.data.DataLoader(train, shuffle=False,**kwargs)\n",
    "test = torch.utils.data.TensorDataset(ot,ut)\n",
    "test_loader = torch.utils.data.DataLoader(test, shuffle=False,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixyz.models import Model\n",
    "from pixyz.losses import KullbackLeibler, CrossEntropy, IterativeLoss, StochasticReconstructionLoss\n",
    "from pixyz.distributions import Bernoulli, Normal, Deterministic\n",
    "from pixyz.utils import print_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(Deterministic):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__(cond_var=[\"x\"], var=[\"h\"])\n",
    "        self.rnn = nn.GRU(x_dim, h_dim, bidirectional=True)\n",
    "#         self.h0 = torch.zeros(2, batch_size, self.rnn.hidden_size).to(device)\n",
    "        self.h0 = nn.Parameter(torch.zeros(2, 1, self.rnn.hidden_size))\n",
    "        self.hidden_size = self.rnn.hidden_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = self.h0.expand(2, x.size(1), self.rnn.hidden_size).contiguous()\n",
    "        h, _ = self.rnn(x, h0)\n",
    "        return {\"h\": h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Generator(Bernoulli):\n",
    "#     def __init__(self):\n",
    "#         super(Generator, self).__init__(cond_var=[\"z\"], var=[\"x\"])\n",
    "#         self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
    "#         self.fc2 = nn.Linear(hidden_dim, x_dim)\n",
    "    \n",
    "#     def forward(self, z):\n",
    "#         print(z.size()) #[128,3]\n",
    "#         h = F.relu(self.fc1(z))\n",
    "#         return {\"probs\": torch.sigmoid(self.fc2(h))}\n",
    "class Generator(Normal):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__(cond_var=[\"z\"], var=[\"x\"])\n",
    "    \n",
    "    def forward(self, z):#計測モデルそのまま\n",
    "        ot=get_all_ot(z,landmark,[1000,1000])\n",
    "        ot=ot_normal(ot,range_ot) #データを正規化しなおしてる\n",
    "        return {\"loc\": ot,\"scale\":torch.tensor(0.1).to(device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference(Normal):\n",
    "    def __init__(self):\n",
    "        super(Inference, self).__init__(cond_var=[\"h\", \"z_prev\"], var=[\"z\"])\n",
    "        self.fc1 = nn.Linear(z_dim, h_dim*2)\n",
    "        self.fc21 = nn.Linear(h_dim*2, z_dim)\n",
    "        self.fc22 = nn.Linear(h_dim*2, z_dim)\n",
    "        \n",
    "    def forward(self, h, z_prev):\n",
    "        h_z = torch.tanh(self.fc1(z_prev))\n",
    "        h = 0.5 * (h + h_z)\n",
    "        return {\"loc\": self.fc21(h), \"scale\": F.softplus(self.fc22(h))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prior(Normal):\n",
    "    def __init__(self):\n",
    "        super(Prior, self).__init__(cond_var=[\"z_prev\",\"u\"], var=[\"z\"])\n",
    "        \n",
    "    def forward(self, z_prev, u):\n",
    "        # motion model for two-wheel robot x,y,orient,v,steering\n",
    "        z = torch.zeros(len(z_prev),z_dim).to(device)\n",
    "        uv=normalize(u[:,0],range_ut[0][0],range_ut[0][1])\n",
    "        ur=normalize(u[:,1],range_ut[1][0],range_ut[1][1])\n",
    "        \n",
    "        z[:,2] = z_prev[:,2] + ur\n",
    "        z[:,0] = z_prev[:,0] + uv * torch.cos(z_prev[:,2] + ur)\n",
    "        z[:,1] = z_prev[:,1] + uv * torch.sin(z_prev[:,2] + ur)\n",
    "\n",
    "        return {\"loc\": z, \"scale\": torch.tensor(0.3).to(device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = Prior().to(device)\n",
    "encoder = Inference().to(device)\n",
    "decoder = Generator().to(device)\n",
    "rnn = RNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p(z|z_{prev},u)\n",
      "Network architecture:\n",
      "  Prior(\n",
      "    name=p, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['z_prev', 'u'], input_var=['z_prev', 'u'], features_shape=torch.Size([])\n",
      "  )\n",
      "********************************************************************************\n",
      "Distribution:\n",
      "  p(z|h,z_{prev})\n",
      "Network architecture:\n",
      "  Inference(\n",
      "    name=p, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['h', 'z_prev'], input_var=['h', 'z_prev'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=3, out_features=64, bias=True)\n",
      "    (fc21): Linear(in_features=64, out_features=3, bias=True)\n",
      "    (fc22): Linear(in_features=64, out_features=3, bias=True)\n",
      "  )\n",
      "********************************************************************************\n",
      "Distribution:\n",
      "  p(x|z)\n",
      "Network architecture:\n",
      "  Generator(\n",
      "    name=p, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['z'], input_var=['z'], features_shape=torch.Size([])\n",
      "  )\n",
      "********************************************************************************\n",
      "Distribution:\n",
      "  p(h|x)\n",
      "Network architecture:\n",
      "  RNN(\n",
      "    name=p, distribution_name=Deterministic,\n",
      "    var=['h'], cond_var=['x'], input_var=['x'], features_shape=torch.Size([])\n",
      "    (rnn): GRU(20, 32)\n",
      "  )\n"
     ]
    }
   ],
   "source": [
    "print(prior)\n",
    "print(\"*\"*80)\n",
    "print(encoder)\n",
    "print(\"*\"*80)\n",
    "print(decoder)\n",
    "print(\"*\"*80)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p(x,z|z_{prev},u) = p(x|z)p(z|z_{prev},u)\n",
      "Network architecture:\n",
      "  Prior(\n",
      "    name=p, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['z_prev', 'u'], input_var=['z_prev', 'u'], features_shape=torch.Size([])\n",
      "  )\n",
      "  Generator(\n",
      "    name=p, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['z'], input_var=['z'], features_shape=torch.Size([])\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle p(x,z|z_{prev},u) = p(x|z)p(z|z_{prev},u)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_from_prior = prior * decoder\n",
    "print(generate_from_prior)\n",
    "print_latex(generate_from_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_loss = CrossEntropy(encoder, decoder) + KullbackLeibler(encoder, prior)\n",
    "_loss = IterativeLoss(step_loss, max_iter=t_max, \n",
    "                      series_var=[\"x\", \"h\", \"u\"], update_value={\"z\": \"z_prev\"})\n",
    "# loss = _loss\n",
    "loss = _loss.expectation(rnn).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmm = Model(loss, distributions=[rnn, encoder, decoder, prior], \n",
    "            optimizer=optim.RMSprop, optimizer_params={\"lr\": 5e-4}, clip_grad_value=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributions (for training): \n",
      "  p(h|x), p(z|h,z_{prev}), p(x|z), p(z|z_{prev},u) \n",
      "Loss function: \n",
      "  \\sum_{t=1}^{66} - \\mathbb{E}_{p(z|h,z_{prev})} \\left[\\log p(x|z) \\right] \n",
      "Optimizer: \n",
      "  RMSprop (\n",
      "  Parameter Group 0\n",
      "      alpha: 0.99\n",
      "      centered: False\n",
      "      eps: 1e-08\n",
      "      lr: 0.0005\n",
      "      momentum: 0\n",
      "      weight_decay: 0\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{t=1}^{66} - \\mathbb{E}_{p(z|h,z_{prev})} \\left[\\log p(x|z) \\right]$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dmm)\n",
    "print_latex(dmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loop(epoch, loader, model, device, train_mode=False):\n",
    "    mean_loss = 0\n",
    "    for idx,[o,u] in enumerate(tqdm(loader)):#batch_idx, (data, _) in enumerate(tqdm(loader)):\n",
    "        o = o.to(device)\n",
    "        u = u.to(device)\n",
    "        batch_size = o.size()[0]\n",
    "        x = o.transpose(0, 1) #多分転置してるだけ\n",
    "        u = u.transpose(0, 1)\n",
    "        z_prev = torch.tensor(start_pos)#初期姿勢\n",
    "        z_prev = z_prev.repeat(batch_size, 1).to(device)\n",
    "        if train_mode:\n",
    "            mean_loss += model.train({'x': x, 'u':u, 'z_prev': z_prev}).item() * batch_size\n",
    "        else:\n",
    "            mean_loss += model.test({'x': x, 'u':u, 'z_prev': z_prev}).item() * batch_size\n",
    "    mean_loss /= len(loader.dataset)\n",
    "    if train_mode:\n",
    "        print('Epoch: {} Train loss: {:.4f}'.format(epoch, mean_loss))\n",
    "    else:\n",
    "        print('Test loss: {:.4f}'.format(mean_loss))\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_from_latent(batch_size):\n",
    "    x = []\n",
    "    z_prev = torch.zeros(batch_size, z_dim).to(device)\n",
    "    u0 = torch.zeros(batch_size, u_dim).to(device)\n",
    "    for step in range(t_max):\n",
    "        samples = generate_from_prior.sample({'z_prev': z_prev,'u':u0})\n",
    "        x_t = decoder.sample_mean({\"z\": samples[\"z\"]})\n",
    "        z_prev = samples[\"z\"]\n",
    "        x.append(x_t[None, :])\n",
    "    x = torch.cat(x, dim=0).transpose(0, 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input keys are not valid, expected ['z_prev', 'h'] but got ['x', 'u', 'z_prev'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-dd8b88ebe7c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-8f0108dd15b4>\u001b[0m in \u001b[0;36mdata_loop\u001b[0;34m(epoch, loader, model, device, train_mode)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mz_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mmean_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'u'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'z_prev'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz_prev\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mmean_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'u'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'z_prev'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz_prev\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pixyz/lib/python3.7/site-packages/pixyz/models/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_x_dict, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;31m# backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pixyz/lib/python3.7/site-packages/pixyz/losses/losses.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, x_dict, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             raise ValueError(\"Input keys are not valid, expected {} but got {}.\".format(self._input_var,\n\u001b[0;32m--> 206\u001b[0;31m                                                                                         list(x_dict.keys())))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input keys are not valid, expected ['z_prev', 'h'] but got ['x', 'u', 'z_prev']."
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "history = {\"train_loss\":[],\"test_loss\":[]}\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = data_loop(epoch, train_loader, dmm, device, train_mode=True)\n",
    "    test_loss = data_loop(epoch, test_loader, dmm, device)\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('test_loss', test_loss, epoch)\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"test_loss\"].append(test_loss)\n",
    "    \n",
    "    sample = plot_image_from_latent(batch_size)[:, None][1,:]\n",
    "    writer.add_image('Image_from_latent', sample, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ylabel('$loss$', fontsize=16)\n",
    "plt.xlabel('$epoch$', fontsize=16)\n",
    "ay=plt.gca()\n",
    "plt.title(\"train_loss\")\n",
    "plt.plot(range(epochs), [i+0.5 for i in history[\"train_loss\"]])\n",
    "plt.show()\n",
    "ay=plt.gca()\n",
    "plt.title(\"test_loss\")\n",
    "plt.plot(range(epochs), [i+0.4 for i in history[\"test_loss\"]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "inference_net = rnn*encoder\n",
    "test_o = data[0,:,(1+z_dim+u_dim):(1+z_dim+u_dim+x_dim)]\n",
    "test_o = torch.tensor(test_o).reshape(1,len(test_o),20).to(device)\n",
    "z_prev = torch.tensor(start_pos).to(device)\n",
    "infered_result = inference_net.sample({\"x\":test_o,\"z_prev\":z_prev})[\"z\"].to(\"cpu\")\n",
    "infered_result=infered_result.numpy()\n",
    "\n",
    "plt.plot(infered_result[:,:, 0], infered_result[:,:, 1], \"co\")\n",
    "for i in range(len(infered_result[0])-1):\n",
    "    plt.plot([infered_result[0][i][0],infered_result[0][i+1][0]],[infered_result[0][i][1],infered_result[0][i+1][1]],\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
