{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Markov Model with motion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2af833e35490>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128#128\n",
    "epochs = 100\n",
    "seed = 1\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#計測モデルとか\n",
    "def get_ot(st,lmap,max_range):\n",
    "    dis = torch.sqrt((st[:,0]-lmap[0])**2+(st[:,1]-lmap[1])**2)\n",
    "    angle = torch.atan2((lmap[1]-st[:,1]),(lmap[0]-st[:,0]))-st[:,2]\n",
    "    return torch.stack([dis,angle],1)\n",
    "    \n",
    "def get_all_ot(st,lmap,max_range):\n",
    "    measure = get_ot(st,lmap[0],max_range)\n",
    "    for l in range(1,len(lmap)):\n",
    "        measure = torch.cat([measure, get_ot(st,lmap[l],max_range)],1)\n",
    "    return torch.tensor(measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_num = 10\n",
    "start_pos = [2.0,4.0,0.0]#x0,y0,yaw0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_dim = 2\n",
    "x_dim = landmark_num*2\n",
    "h_dim = 32 #32\n",
    "hidden_dim = 32 #32\n",
    "z_dim = 3\n",
    "u_dim = 2\n",
    "t_max = 89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, *args):\n",
    "    if len(args) == 0:\n",
    "        max_data = torch.max(abs(data))\n",
    "        data=data/max_data\n",
    "    else :\n",
    "        max_data=torch.max(abs(torch.tensor(args)))\n",
    "        data=data/max_data\n",
    "    return data\n",
    "\n",
    "def normalize(data, *args):\n",
    "    if len(args) == 0:#未実装\n",
    "        max_data = torch.max(abs(data))\n",
    "        data=data/max_data\n",
    "    else :\n",
    "        max_data=torch.max(abs(torch.tensor(args)))\n",
    "        data=data*max_data\n",
    "    return data\n",
    "\n",
    "def ot_normal(ot,range_ot):\n",
    "    ot=ot.view(len(ot),10,2)\n",
    "    ot[:,:,0]=normalize(ot[:,:,0],range_ot[0][0],range_ot[0][1])\n",
    "    ot[:,:,1]=normalize(ot[:,:,1],range_ot[1][0],range_ot[1][1])\n",
    "    ot = ot.view(len(ot),20)\n",
    "    return ot\n",
    "\n",
    "def inv_ot_normal(ot,range_ot):\n",
    "    ot=ot.view(len(ot),10,2)\n",
    "    ot[:,:,0]=ot[:,:,0]*torch.max(range_ot[0][0],range_ot[0][1])\n",
    "    ot[:,:,1]=ot[:,:,1]*torch.max(range_ot[1][0],range_ot[1][1])\n",
    "    ot = ot.view(len(ot),20)\n",
    "    return ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  0.0000e+00],\n",
      "        [ 4.0000e-01,  5.9341e-01],\n",
      "        [ 8.0000e-01,  2.2689e-01],\n",
      "        [ 1.2000e+00,  1.0472e-01],\n",
      "        [ 1.6000e+00,  3.4907e-02],\n",
      "        [ 2.0000e+00,  1.7453e-02],\n",
      "        [ 2.4000e+00,  5.4401e-15],\n",
      "        [ 2.8000e+00,  6.4393e-15],\n",
      "        [ 3.2000e+00,  7.4385e-15],\n",
      "        [ 3.6000e+00,  8.4377e-15],\n",
      "        [ 4.0000e+00,  9.4369e-15],\n",
      "        [ 4.4000e+00,  1.0436e-14],\n",
      "        [ 4.8000e+00,  1.1435e-14],\n",
      "        [ 4.9000e+00,  1.2434e-14],\n",
      "        [ 4.9000e+00,  1.3434e-14],\n",
      "        [ 5.0000e+00,  1.4433e-14],\n",
      "        [ 5.0000e+00,  1.5432e-14],\n",
      "        [ 5.0000e+00,  1.6431e-14],\n",
      "        [ 5.0000e+00,  1.7431e-14],\n",
      "        [ 5.0000e+00,  1.8430e-14],\n",
      "        [ 5.0000e+00,  1.9429e-14],\n",
      "        [ 5.0000e+00,  2.0428e-14],\n",
      "        [ 5.0000e+00,  2.1427e-14],\n",
      "        [ 5.0000e+00,  1.7453e-02],\n",
      "        [ 5.0000e+00,  2.3426e-14],\n",
      "        [ 5.0000e+00,  2.4425e-14],\n",
      "        [ 4.5000e+00,  2.5424e-14],\n",
      "        [ 4.0000e+00,  2.6423e-14],\n",
      "        [ 4.4000e+00, -6.9813e-01],\n",
      "        [ 4.8000e+00, -6.9813e-01],\n",
      "        [ 5.0000e+00, -6.9813e-01],\n",
      "        [ 5.0000e+00, -5.5851e-01],\n",
      "        [ 5.0000e+00, -2.4435e-01],\n",
      "        [ 5.0000e+00, -1.2217e-01],\n",
      "        [ 5.0000e+00, -6.9813e-02],\n",
      "        [ 4.5000e+00, -3.4907e-02],\n",
      "        [ 4.0000e+00, -1.7453e-02],\n",
      "        [ 4.4000e+00,  6.8068e-01],\n",
      "        [ 4.8000e+00,  6.8068e-01],\n",
      "        [ 5.0000e+00,  6.8068e-01],\n",
      "        [ 5.0000e+00,  6.6323e-01],\n",
      "        [ 5.0000e+00,  2.9671e-01],\n",
      "        [ 5.0000e+00,  1.2217e-01],\n",
      "        [ 5.0000e+00,  5.2360e-02],\n",
      "        [ 5.0000e+00,  1.7453e-02],\n",
      "        [ 5.0000e+00,  1.7453e-02],\n",
      "        [ 5.0000e+00,  6.5503e-15],\n",
      "        [ 5.0000e+00,  1.7453e-02],\n",
      "        [ 5.0000e+00,  8.5487e-15],\n",
      "        [ 5.0000e+00,  9.5479e-15],\n",
      "        [ 4.5000e+00,  1.0547e-14],\n",
      "        [ 4.0000e+00, -1.7453e-02],\n",
      "        [ 4.4000e+00, -6.9813e-01],\n",
      "        [ 4.8000e+00, -6.9813e-01],\n",
      "        [ 5.0000e+00, -6.9813e-01],\n",
      "        [ 5.0000e+00, -4.5379e-01],\n",
      "        [ 5.0000e+00, -1.9199e-01],\n",
      "        [ 5.0000e+00, -8.7266e-02],\n",
      "        [ 5.0000e+00, -3.4907e-02],\n",
      "        [ 5.0000e+00, -1.7453e-02],\n",
      "        [ 5.0000e+00,  9.9920e-16],\n",
      "        [ 5.0000e+00,  1.9984e-15],\n",
      "        [ 5.0000e+00,  2.9976e-15],\n",
      "        [ 5.0000e+00,  3.9968e-15],\n",
      "        [ 5.0000e+00,  4.9960e-15],\n",
      "        [ 4.5000e+00, -1.7453e-02],\n",
      "        [ 4.0000e+00,  9.9920e-16],\n",
      "        [ 3.5000e+00, -6.9813e-01],\n",
      "        [ 3.0000e+00, -6.9813e-01],\n",
      "        [ 2.5000e+00, -6.9813e-01],\n",
      "        [ 2.9000e+00, -6.9813e-01],\n",
      "        [ 3.3000e+00, -6.9813e-01],\n",
      "        [ 3.7000e+00, -6.9813e-01],\n",
      "        [ 3.7000e+00, -6.9813e-01],\n",
      "        [ 3.2000e+00, -6.9813e-01],\n",
      "        [ 2.7000e+00, -6.9813e-01],\n",
      "        [ 2.2000e+00, -6.9813e-01],\n",
      "        [ 1.7000e+00, -6.9813e-01],\n",
      "        [ 1.9000e+00, -6.9813e-01],\n",
      "        [ 2.2000e+00, -6.9813e-01],\n",
      "        [ 2.3000e+00, -6.9813e-01],\n",
      "        [ 2.2000e+00, -6.9813e-01],\n",
      "        [ 2.0000e+00, -6.9813e-01],\n",
      "        [ 1.8000e+00, -6.9813e-01],\n",
      "        [ 1.5000e+00, -6.9813e-01],\n",
      "        [ 1.3000e+00, -6.9813e-01],\n",
      "        [ 1.0000e+00, -6.9813e-01],\n",
      "        [ 8.0000e-01, -6.9813e-01],\n",
      "        [ 7.0000e-01, -6.9813e-01]])\n",
      "tensor([[ 0.0000e+00,  0.0000e+00],\n",
      "        [ 2.0000e+00,  9.3213e-01],\n",
      "        [ 4.0000e+00,  3.5640e-01],\n",
      "        [ 6.0000e+00,  1.6449e-01],\n",
      "        [ 8.0000e+00,  5.4831e-02],\n",
      "        [ 1.0000e+01,  2.7416e-02],\n",
      "        [ 1.2000e+01,  8.5453e-15],\n",
      "        [ 1.4000e+01,  1.0115e-14],\n",
      "        [ 1.6000e+01,  1.1684e-14],\n",
      "        [ 1.8000e+01,  1.3254e-14],\n",
      "        [ 2.0000e+01,  1.4823e-14],\n",
      "        [ 2.2000e+01,  1.6393e-14],\n",
      "        [ 2.4000e+01,  1.7963e-14],\n",
      "        [ 2.4500e+01,  1.9532e-14],\n",
      "        [ 2.4500e+01,  2.1102e-14],\n",
      "        [ 2.5000e+01,  2.2671e-14],\n",
      "        [ 2.5000e+01,  2.4241e-14],\n",
      "        [ 2.5000e+01,  2.5810e-14],\n",
      "        [ 2.5000e+01,  2.7380e-14],\n",
      "        [ 2.5000e+01,  2.8949e-14],\n",
      "        [ 2.5000e+01,  3.0519e-14],\n",
      "        [ 2.5000e+01,  3.2088e-14],\n",
      "        [ 2.5000e+01,  3.3658e-14],\n",
      "        [ 2.5000e+01,  2.7416e-02],\n",
      "        [ 2.5000e+01,  3.6797e-14],\n",
      "        [ 2.5000e+01,  3.8367e-14],\n",
      "        [ 2.2500e+01,  3.9936e-14],\n",
      "        [ 2.0000e+01,  4.1506e-14],\n",
      "        [ 2.2000e+01, -1.0966e+00],\n",
      "        [ 2.4000e+01, -1.0966e+00],\n",
      "        [ 2.5000e+01, -1.0966e+00],\n",
      "        [ 2.5000e+01, -8.7730e-01],\n",
      "        [ 2.5000e+01, -3.8382e-01],\n",
      "        [ 2.5000e+01, -1.9191e-01],\n",
      "        [ 2.5000e+01, -1.0966e-01],\n",
      "        [ 2.2500e+01, -5.4831e-02],\n",
      "        [ 2.0000e+01, -2.7416e-02],\n",
      "        [ 2.2000e+01,  1.0692e+00],\n",
      "        [ 2.4000e+01,  1.0692e+00],\n",
      "        [ 2.5000e+01,  1.0692e+00],\n",
      "        [ 2.5000e+01,  1.0418e+00],\n",
      "        [ 2.5000e+01,  4.6606e-01],\n",
      "        [ 2.5000e+01,  1.9191e-01],\n",
      "        [ 2.5000e+01,  8.2247e-02],\n",
      "        [ 2.5000e+01,  2.7416e-02],\n",
      "        [ 2.5000e+01,  2.7416e-02],\n",
      "        [ 2.5000e+01,  1.0289e-14],\n",
      "        [ 2.5000e+01,  2.7416e-02],\n",
      "        [ 2.5000e+01,  1.3428e-14],\n",
      "        [ 2.5000e+01,  1.4998e-14],\n",
      "        [ 2.2500e+01,  1.6567e-14],\n",
      "        [ 2.0000e+01, -2.7416e-02],\n",
      "        [ 2.2000e+01, -1.0966e+00],\n",
      "        [ 2.4000e+01, -1.0966e+00],\n",
      "        [ 2.5000e+01, -1.0966e+00],\n",
      "        [ 2.5000e+01, -7.1280e-01],\n",
      "        [ 2.5000e+01, -3.0157e-01],\n",
      "        [ 2.5000e+01, -1.3708e-01],\n",
      "        [ 2.5000e+01, -5.4831e-02],\n",
      "        [ 2.5000e+01, -2.7416e-02],\n",
      "        [ 2.5000e+01,  1.5695e-15],\n",
      "        [ 2.5000e+01,  3.1391e-15],\n",
      "        [ 2.5000e+01,  4.7086e-15],\n",
      "        [ 2.5000e+01,  6.2782e-15],\n",
      "        [ 2.5000e+01,  7.8477e-15],\n",
      "        [ 2.2500e+01, -2.7416e-02],\n",
      "        [ 2.0000e+01,  1.5695e-15],\n",
      "        [ 1.7500e+01, -1.0966e+00],\n",
      "        [ 1.5000e+01, -1.0966e+00],\n",
      "        [ 1.2500e+01, -1.0966e+00],\n",
      "        [ 1.4500e+01, -1.0966e+00],\n",
      "        [ 1.6500e+01, -1.0966e+00],\n",
      "        [ 1.8500e+01, -1.0966e+00],\n",
      "        [ 1.8500e+01, -1.0966e+00],\n",
      "        [ 1.6000e+01, -1.0966e+00],\n",
      "        [ 1.3500e+01, -1.0966e+00],\n",
      "        [ 1.1000e+01, -1.0966e+00],\n",
      "        [ 8.5000e+00, -1.0966e+00],\n",
      "        [ 9.5000e+00, -1.0966e+00],\n",
      "        [ 1.1000e+01, -1.0966e+00],\n",
      "        [ 1.1500e+01, -1.0966e+00],\n",
      "        [ 1.1000e+01, -1.0966e+00],\n",
      "        [ 1.0000e+01, -1.0966e+00],\n",
      "        [ 9.0000e+00, -1.0966e+00],\n",
      "        [ 7.5000e+00, -1.0966e+00],\n",
      "        [ 6.5000e+00, -1.0966e+00],\n",
      "        [ 5.0000e+00, -1.0966e+00],\n",
      "        [ 4.0000e+00, -1.0966e+00],\n",
      "        [ 3.5000e+00, -1.0966e+00]])\n",
      "torch.Size([89, 3])\n",
      "torch.Size([1000, 89, 3])\n"
     ]
    }
   ],
   "source": [
    "#データの読み込み\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "kwargs = {'batch_size': batch_size, 'num_workers': 1, 'pin_memory': True}\n",
    "\n",
    "range_ot=torch.tensor([[0.0,150.0],[-np.pi*2,np.pi*2]])#otの[dis,theta]の最大と最小\n",
    "range_ut=torch.tensor([[0.0,5.0],[-np.pi/2.0,np.pi/2.0]])#utの[v,r]\n",
    "\n",
    "#data loader #とりあえず1時系列分を分身させて食わせてる\n",
    "#[time,s_x,s_y,s_yaw,uv,ur,ot[1],,,,ot[N]]\n",
    "data = np.loadtxt('vehicle_motion_data.csv', delimiter=',')\n",
    "data = torch.tensor([data],dtype=torch.float32)\n",
    "st = data[0,:,1:(1+z_dim)]\n",
    "ut = data[0,:,(1+z_dim):(1+z_dim+u_dim)]\n",
    "ot = data[0,:,(1+z_dim+u_dim):(1+z_dim+u_dim+x_dim)]\n",
    "t_max = len(ot)\n",
    "ot=ot_normal(ot,range_ot)\n",
    "\n",
    "ut[:,0]=normalize(ut[:,0],range_ut[0][0],range_ut[0][1])\n",
    "ut[:,1]=normalize(ut[:,1],range_ut[1][0],range_ut[1][1])\n",
    "\n",
    "print(st.size())\n",
    "st=st.repeat(1000,1,1)\n",
    "ut=ut.repeat(1000,1,1)\n",
    "ot=ot.repeat(1000,1,1)\n",
    "print(st.size())\n",
    "\n",
    "\n",
    "landmark = np.loadtxt('landmark_data.csv',delimiter=',')\n",
    "\n",
    "train = torch.utils.data.TensorDataset(ot,ut)\n",
    "train_loader = torch.utils.data.DataLoader(train, shuffle=False,**kwargs)\n",
    "test = torch.utils.data.TensorDataset(ot,ut)\n",
    "test_loader = torch.utils.data.DataLoader(test, shuffle=False,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixyz.models import Model\n",
    "from pixyz.losses import KullbackLeibler, CrossEntropy, IterativeLoss, StochasticReconstructionLoss\n",
    "from pixyz.distributions import Bernoulli, Normal, Deterministic\n",
    "from pixyz.utils import print_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(Deterministic):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__(cond_var=[\"x\"], var=[\"h\"])\n",
    "        self.rnn = nn.GRU(x_dim, h_dim, bidirectional=True)\n",
    "#         self.h0 = torch.zeros(2, batch_size, self.rnn.hidden_size).to(device)\n",
    "        self.h0 = nn.Parameter(torch.zeros(2, 1, self.rnn.hidden_size))\n",
    "        self.hidden_size = self.rnn.hidden_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = self.h0.expand(2, x.size(1), self.rnn.hidden_size).contiguous()\n",
    "        h, _ = self.rnn(x, h0)\n",
    "        return {\"h\": h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Generator(Bernoulli):\n",
    "#     def __init__(self):\n",
    "#         super(Generator, self).__init__(cond_var=[\"z\"], var=[\"x\"])\n",
    "#         self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
    "#         self.fc2 = nn.Linear(hidden_dim, x_dim)\n",
    "    \n",
    "#     def forward(self, z):\n",
    "#         print(z.size()) #[128,3]\n",
    "#         h = F.relu(self.fc1(z))\n",
    "#         return {\"probs\": torch.sigmoid(self.fc2(h))}\n",
    "class Generator(Normal):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__(cond_var=[\"z\"], var=[\"x\"])\n",
    "    \n",
    "    def forward(self, z):#計測モデルそのまま\n",
    "        ot=get_all_ot(z,landmark,[1000,1000])\n",
    "        ot=ot_normal(ot,range_ot) #データを正規化しなおしてる\n",
    "        return {\"loc\": ot,\"scale\":torch.tensor(0.1).to(device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference(Normal):\n",
    "    def __init__(self):\n",
    "        super(Inference, self).__init__(cond_var=[\"h\", \"z_prev\"], var=[\"z\"])\n",
    "        self.fc1 = nn.Linear(z_dim, h_dim*2)\n",
    "        self.fc21 = nn.Linear(h_dim*2, z_dim)\n",
    "        self.fc22 = nn.Linear(h_dim*2, z_dim)\n",
    "        \n",
    "    def forward(self, h, z_prev):\n",
    "        h_z = torch.tanh(self.fc1(z_prev))\n",
    "        h = 0.5 * (h + h_z)\n",
    "        return {\"loc\": self.fc21(h), \"scale\": F.softplus(self.fc22(h))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prior(Normal):\n",
    "    def __init__(self):\n",
    "        super(Prior, self).__init__(cond_var=[\"z_prev\",\"u\"], var=[\"z\"])\n",
    "        \n",
    "    def forward(self, z_prev, u):\n",
    "        # motion model for two-wheel robot x,y,orient,v,steering\n",
    "        z = torch.zeros(len(z_prev),z_dim).to(device)\n",
    "        uv=normalize(u[:,0],range_ut[0][0],range_ut[0][1])\n",
    "        ur=normalize(u[:,1],range_ut[1][0],range_ut[1][1])\n",
    "        \n",
    "        z[:,2] = z_prev[:,2] + ur\n",
    "        z[:,0] = z_prev[:,0] + uv * torch.cos(z_prev[:,2] + ur)\n",
    "        z[:,1] = z_prev[:,1] + uv * torch.sin(z_prev[:,2] + ur)\n",
    "\n",
    "        return {\"loc\": z, \"scale\": torch.tensor(0.3).to(device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = Prior().to(device)\n",
    "encoder = Inference().to(device)\n",
    "decoder = Generator().to(device)\n",
    "rnn = RNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p(z|z_{prev},u)\n",
      "Network architecture:\n",
      "  Prior(\n",
      "    name=p, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['z_prev', 'u'], input_var=['z_prev', 'u'], features_shape=torch.Size([])\n",
      "  )\n",
      "********************************************************************************\n",
      "Distribution:\n",
      "  p(z|h,z_{prev})\n",
      "Network architecture:\n",
      "  Inference(\n",
      "    name=p, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['h', 'z_prev'], input_var=['h', 'z_prev'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=3, out_features=64, bias=True)\n",
      "    (fc21): Linear(in_features=64, out_features=3, bias=True)\n",
      "    (fc22): Linear(in_features=64, out_features=3, bias=True)\n",
      "  )\n",
      "********************************************************************************\n",
      "Distribution:\n",
      "  p(x|z)\n",
      "Network architecture:\n",
      "  Generator(\n",
      "    name=p, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['z'], input_var=['z'], features_shape=torch.Size([])\n",
      "  )\n",
      "********************************************************************************\n",
      "Distribution:\n",
      "  p(h|x)\n",
      "Network architecture:\n",
      "  RNN(\n",
      "    name=p, distribution_name=Deterministic,\n",
      "    var=['h'], cond_var=['x'], input_var=['x'], features_shape=torch.Size([])\n",
      "    (rnn): GRU(20, 32, bidirectional=True)\n",
      "  )\n"
     ]
    }
   ],
   "source": [
    "print(prior)\n",
    "print(\"*\"*80)\n",
    "print(encoder)\n",
    "print(\"*\"*80)\n",
    "print(decoder)\n",
    "print(\"*\"*80)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p(x,z|z_{prev},u) = p(x|z)p(z|z_{prev},u)\n",
      "Network architecture:\n",
      "  Prior(\n",
      "    name=p, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['z_prev', 'u'], input_var=['z_prev', 'u'], features_shape=torch.Size([])\n",
      "  )\n",
      "  Generator(\n",
      "    name=p, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['z'], input_var=['z'], features_shape=torch.Size([])\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle p(x,z|z_{prev},u) = p(x|z)p(z|z_{prev},u)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_from_prior = prior * decoder\n",
    "print(generate_from_prior)\n",
    "print_latex(generate_from_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_loss = CrossEntropy(encoder, decoder) + KullbackLeibler(encoder, prior)\n",
    "_loss = IterativeLoss(step_loss, max_iter=t_max, \n",
    "                      series_var=[\"x\", \"h\", \"u\"], update_value={\"z\": \"z_prev\"})\n",
    "loss = _loss.expectation(rnn).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmm = Model(loss, distributions=[rnn, encoder, decoder, prior], \n",
    "            optimizer=optim.RMSprop, optimizer_params={\"lr\": 5e-4}, clip_grad_value=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributions (for training): \n",
      "  p(h|x), p(z|h,z_{prev}), p(x|z), p(z|z_{prev},u) \n",
      "Loss function: \n",
      "  mean \\left(\\mathbb{E}_{p(h|x)} \\left[\\sum_{t=1}^{89} \\left(D_{KL} \\left[p(z|h,z_{prev})||p(z|z_{prev},u) \\right] - \\mathbb{E}_{p(z|h,z_{prev})} \\left[\\log p(x|z) \\right]\\right) \\right] \\right) \n",
      "Optimizer: \n",
      "  RMSprop (\n",
      "  Parameter Group 0\n",
      "      alpha: 0.99\n",
      "      centered: False\n",
      "      eps: 1e-08\n",
      "      lr: 0.0005\n",
      "      momentum: 0\n",
      "      weight_decay: 0\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle mean \\left(\\mathbb{E}_{p(h|x)} \\left[\\sum_{t=1}^{89} \\left(D_{KL} \\left[p(z|h,z_{prev})||p(z|z_{prev},u) \\right] - \\mathbb{E}_{p(z|h,z_{prev})} \\left[\\log p(x|z) \\right]\\right) \\right] \\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dmm)\n",
    "print_latex(dmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loop(epoch, loader, model, device, train_mode=False):\n",
    "    mean_loss = 0\n",
    "    for idx,[o,u] in enumerate(tqdm(loader)):#batch_idx, (data, _) in enumerate(tqdm(loader)):\n",
    "        o = o.to(device)\n",
    "        u = u.to(device)\n",
    "        batch_size = o.size()[0]\n",
    "        x = o.transpose(0, 1) #多分転置してるだけ\n",
    "        u = u.transpose(0, 1)\n",
    "        z_prev = torch.tensor(start_pos)#初期姿勢\n",
    "        z_prev = z_prev.repeat(batch_size, 1).to(device)\n",
    "        if train_mode:\n",
    "            mean_loss += model.train({'x': x, 'u':u, 'z_prev': z_prev}).item() * batch_size\n",
    "        else:\n",
    "            mean_loss += model.test({'x': x, 'u':u, 'z_prev': z_prev}).item() * batch_size\n",
    "    mean_loss /= len(loader.dataset)\n",
    "    if train_mode:\n",
    "        print('Epoch: {} Train loss: {:.4f}'.format(epoch, mean_loss))\n",
    "    else:\n",
    "        print('Test loss: {:.4f}'.format(mean_loss))\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_from_latent(batch_size):\n",
    "    x = []\n",
    "    z_prev = torch.zeros(batch_size, z_dim).to(device)\n",
    "    u0 = torch.zeros(batch_size, u_dim).to(device)\n",
    "    for step in range(t_max):\n",
    "        samples = generate_from_prior.sample({'z_prev': z_prev,'u':u0})\n",
    "        x_t = decoder.sample_mean({\"z\": samples[\"z\"]})\n",
    "        z_prev = samples[\"z\"]\n",
    "        x.append(x_t[None, :])\n",
    "    x = torch.cat(x, dim=0).transpose(0, 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/fukku/anaconda3/envs/pixyz/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "100%|██████████| 8/8 [00:05<00:00,  1.60it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 3031694810546.1758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3032671894634.4961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.58it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train loss: 3034742863691.7759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3037337101533.1841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.57it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train loss: 3039100380643.3281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3041488715907.0718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.57it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Train loss: 3043268627529.7280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3045946065682.4321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.58it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train loss: 3047637611708.4160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3049768836136.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.59it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Train loss: 3051484528771.0718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3053794728345.6001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.58it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Train loss: 3055387609661.4399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3057615475048.4482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.60it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Train loss: 3059112896102.3999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3061255197687.8081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.63it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Train loss: 3062430240342.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3064395076730.8799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.58it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train loss: 3065885803675.6479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [00:02<00:01,  2.05it/s]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "history = {\"train_loss\":[],\"test_loss\":[]}\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = data_loop(epoch, train_loader, dmm, device, train_mode=True)\n",
    "    test_loss = data_loop(epoch, test_loader, dmm, device)\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('test_loss', test_loss, epoch)\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"test_loss\"].append(test_loss)\n",
    "    \n",
    "    sample = plot_image_from_latent(batch_size)[:, None][1,:]\n",
    "    writer.add_image('Image_from_latent', sample, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ylabel('$loss$', fontsize=16)\n",
    "plt.xlabel('$epoch$', fontsize=16)\n",
    "ay=plt.gca()\n",
    "plt.title(\"train_loss\")\n",
    "plt.plot(range(epochs), [i+0.5 for i in history[\"train_loss\"]])\n",
    "plt.show()\n",
    "ay=plt.gca()\n",
    "plt.title(\"test_loss\")\n",
    "plt.plot(range(epochs), [i+0.4 for i in history[\"test_loss\"]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "inference_net = rnn*encoder\n",
    "test_o = data[0,:,(1+z_dim+u_dim):(1+z_dim+u_dim+x_dim)]\n",
    "test_o = torch.tensor(test_o).reshape(1,len(test_o),20).to(device)\n",
    "z_prev = torch.tensor(start_pos).to(device)\n",
    "infered_result = inference_net.sample({\"x\":test_o,\"z_prev\":z_prev})[\"z\"].to(\"cpu\")\n",
    "infered_result=infered_result.numpy()\n",
    "\n",
    "plt.plot(infered_result[:,:, 0], infered_result[:,:, 1], \"co\")\n",
    "for i in range(len(infered_result[0])-1):\n",
    "    plt.plot([infered_result[0][i][0],infered_result[0][i+1][0]],[infered_result[0][i][1],infered_result[0][i+1][1]],\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
