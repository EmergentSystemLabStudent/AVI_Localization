{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Markov Model for full localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b317be83490>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128#128\n",
    "epochs = 100\n",
    "seed = 1\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#計測モデルとか\n",
    "def get_ot(st,lmap,max_range):\n",
    "    dis = torch.sqrt((st[:,0]-lmap[0])**2+(st[:,1]-lmap[1])**2)\n",
    "    angle = torch.atan2((lmap[1]-st[:,1]),(lmap[0]-st[:,0]))-st[:,2]\n",
    "    return torch.stack([dis,angle],1)\n",
    "    \n",
    "def get_all_ot(st,lmap,max_range):\n",
    "    measure = get_ot(st,lmap[0],max_range)\n",
    "    for l in range(1,len(lmap)):\n",
    "        measure = torch.cat([measure, get_ot(st,lmap[l],max_range)],1)\n",
    "    return torch.tensor(measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_num = 10\n",
    "start_pos = [2.0,4.0,0.0]#x0,y0,yaw0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_dim = 2\n",
    "x_dim = landmark_num*2\n",
    "h_dim = 32 #32\n",
    "hidden_dim = 32 #32\n",
    "z_dim = 3\n",
    "u_dim = 2\n",
    "t_max = 139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([89, 3])\n",
      "torch.Size([1000, 89, 3])\n"
     ]
    }
   ],
   "source": [
    "#データの読み込み\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "kwargs = {'batch_size': batch_size, 'num_workers': 1, 'pin_memory': True}\n",
    "\n",
    "#data loader #とりあえず1時系列分を分身させて食わせてる\n",
    "#[time,s_x,s_y,s_yaw,uv,ur,ot[1],,,,ot[N]]\n",
    "data = np.loadtxt('vehicle_motion_data.csv', delimiter=',')\n",
    "data = torch.tensor([data],dtype=torch.float32)\n",
    "st = data[0,:,1:(1+z_dim)]\n",
    "ut = data[0,:,(1+z_dim):(1+z_dim+u_dim)]\n",
    "ot = data[0,:,(1+z_dim+u_dim):(1+z_dim+u_dim+x_dim)]\n",
    "t_max = len(ot)\n",
    "\n",
    "print(st.size())\n",
    "st=st.repeat(1000,1,1)\n",
    "ut=ut.repeat(1000,1,1)\n",
    "ot=ot.repeat(1000,1,1)\n",
    "print(st.size())\n",
    "\n",
    "\n",
    "landmark = np.loadtxt('landmark_data.csv',delimiter=',')\n",
    "\n",
    "train = torch.utils.data.TensorDataset(ot,ut)\n",
    "train_loader = torch.utils.data.DataLoader(train, shuffle=False,**kwargs)\n",
    "test = torch.utils.data.TensorDataset(ot,ut)\n",
    "test_loader = torch.utils.data.DataLoader(test, shuffle=False,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixyz.models import Model\n",
    "from pixyz.losses import KullbackLeibler, CrossEntropy, IterativeLoss\n",
    "from pixyz.distributions import Bernoulli, Normal, Deterministic\n",
    "from pixyz.utils import print_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(Deterministic):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__(cond_var=[\"x\"], var=[\"h\"])\n",
    "        self.rnn = nn.GRU(x_dim, h_dim, bidirectional=True)\n",
    "#         self.h0 = torch.zeros(2, batch_size, self.rnn.hidden_size).to(device)\n",
    "        self.h0 = nn.Parameter(torch.zeros(2, 1, self.rnn.hidden_size))\n",
    "        self.hidden_size = self.rnn.hidden_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = self.h0.expand(2, x.size(1), self.rnn.hidden_size).contiguous()\n",
    "        h, _ = self.rnn(x, h0)\n",
    "        return {\"h\": h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Generator(Bernoulli):\n",
    "#     def __init__(self):\n",
    "#         super(Generator, self).__init__(cond_var=[\"z\"], var=[\"x\"])\n",
    "#         self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
    "#         self.fc2 = nn.Linear(hidden_dim, x_dim)\n",
    "    \n",
    "#     def forward(self, z):\n",
    "#         print(z.size()) #[128,3]\n",
    "#         h = F.relu(self.fc1(z))\n",
    "#         return {\"probs\": torch.sigmoid(self.fc2(h))}\n",
    "class Generator(Normal):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__(cond_var=[\"z\"], var=[\"x\"])\n",
    "    \n",
    "    def forward(self, z):#計測モデルそのまま\n",
    "        ot=get_all_ot(z,landmark,[1000,1000])\n",
    "        return {\"loc\": ot,\"scale\":torch.tensor(0.3).to(device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference(Normal):\n",
    "    def __init__(self):\n",
    "        super(Inference, self).__init__(cond_var=[\"h\", \"z_prev\", \"u\"], var=[\"z\"])\n",
    "        self.fc1 = nn.Linear(z_dim, h_dim*2)\n",
    "        self.fc2 = nn.Linear(u_dim, h_dim*2)\n",
    "        self.fc31 = nn.Linear(h_dim*2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim*2, z_dim)\n",
    "        \n",
    "    def forward(self, h, z_prev, u):\n",
    "        h_z = torch.tanh(self.fc1(z_prev))\n",
    "        h_u = torch.tanh(self.fc2(u))\n",
    "        h = (1.0/3.0) * (h + h_z + h_u)\n",
    "        return {\"loc\": self.fc31(h), \"scale\": F.softplus(self.fc32(h))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prior(Normal):\n",
    "    def __init__(self):\n",
    "        super(Prior, self).__init__(cond_var=[\"z_prev\",\"u\"], var=[\"z\"])\n",
    "        \n",
    "    def forward(self, z_prev, u):\n",
    "        # motion model for two-wheel robot x,y,orient,v,steering\n",
    "        z = torch.zeros(len(z_prev),z_dim).to(device)\n",
    "        z[:,2] = z_prev[:,2] + u[:,1]\n",
    "        z[:,0] = z_prev[:,0] + u[:,0] * torch.cos(z_prev[:,2] + u[:,1])\n",
    "        z[:,1] = z_prev[:,1] + u[:,0] * torch.sin(z_prev[:,2] + u[:,1])\n",
    "\n",
    "        return {\"loc\": z, \"scale\": torch.tensor(0.3).to(device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = Prior().to(device)\n",
    "encoder = Inference().to(device)\n",
    "decoder = Generator().to(device)\n",
    "rnn = RNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p(z|z_{prev},u)\n",
      "Network architecture:\n",
      "  Prior(\n",
      "    name=p, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['z_prev', 'u'], input_var=['z_prev', 'u'], features_shape=torch.Size([])\n",
      "  )\n",
      "********************************************************************************\n",
      "Distribution:\n",
      "  p(z|h,z_{prev},u)\n",
      "Network architecture:\n",
      "  Inference(\n",
      "    name=p, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['h', 'z_prev', 'u'], input_var=['h', 'z_prev', 'u'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=3, out_features=64, bias=True)\n",
      "    (fc2): Linear(in_features=2, out_features=64, bias=True)\n",
      "    (fc31): Linear(in_features=64, out_features=3, bias=True)\n",
      "    (fc32): Linear(in_features=64, out_features=3, bias=True)\n",
      "  )\n",
      "********************************************************************************\n",
      "Distribution:\n",
      "  p(x|z)\n",
      "Network architecture:\n",
      "  Generator(\n",
      "    name=p, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['z'], input_var=['z'], features_shape=torch.Size([])\n",
      "  )\n",
      "********************************************************************************\n",
      "Distribution:\n",
      "  p(h|x)\n",
      "Network architecture:\n",
      "  RNN(\n",
      "    name=p, distribution_name=Deterministic,\n",
      "    var=['h'], cond_var=['x'], input_var=['x'], features_shape=torch.Size([])\n",
      "    (rnn): GRU(20, 32, bidirectional=True)\n",
      "  )\n"
     ]
    }
   ],
   "source": [
    "print(prior)\n",
    "print(\"*\"*80)\n",
    "print(encoder)\n",
    "print(\"*\"*80)\n",
    "print(decoder)\n",
    "print(\"*\"*80)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p(x,z|z_{prev},u) = p(x|z)p(z|z_{prev},u)\n",
      "Network architecture:\n",
      "  Prior(\n",
      "    name=p, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['z_prev', 'u'], input_var=['z_prev', 'u'], features_shape=torch.Size([])\n",
      "  )\n",
      "  Generator(\n",
      "    name=p, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['z'], input_var=['z'], features_shape=torch.Size([])\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle p(x,z|z_{prev},u) = p(x|z)p(z|z_{prev},u)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_from_prior = prior * decoder\n",
    "print(generate_from_prior)\n",
    "print_latex(generate_from_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_loss = CrossEntropy(encoder, decoder) + KullbackLeibler(encoder, prior)\n",
    "_loss = IterativeLoss(step_loss, max_iter=t_max, \n",
    "                      series_var=[\"x\", \"h\", \"u\"], update_value={\"z\": \"z_prev\"})\n",
    "loss = _loss.expectation(rnn).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmm = Model(loss, distributions=[rnn, encoder, decoder, prior], \n",
    "            optimizer=optim.RMSprop, optimizer_params={\"lr\": 5e-4}, clip_grad_value=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributions (for training): \n",
      "  p(h|x), p(z|h,z_{prev},u), p(x|z), p(z|z_{prev},u) \n",
      "Loss function: \n",
      "  mean \\left(\\mathbb{E}_{p(h|x)} \\left[\\sum_{t=1}^{89} \\left(D_{KL} \\left[p(z|h,z_{prev},u)||p(z|z_{prev},u) \\right] - \\mathbb{E}_{p(z|h,z_{prev},u)} \\left[\\log p(x|z) \\right]\\right) \\right] \\right) \n",
      "Optimizer: \n",
      "  RMSprop (\n",
      "  Parameter Group 0\n",
      "      alpha: 0.99\n",
      "      centered: False\n",
      "      eps: 1e-08\n",
      "      lr: 0.0005\n",
      "      momentum: 0\n",
      "      weight_decay: 0\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle mean \\left(\\mathbb{E}_{p(h|x)} \\left[\\sum_{t=1}^{89} \\left(D_{KL} \\left[p(z|h,z_{prev},u)||p(z|z_{prev},u) \\right] - \\mathbb{E}_{p(z|h,z_{prev},u)} \\left[\\log p(x|z) \\right]\\right) \\right] \\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dmm)\n",
    "print_latex(dmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loop(epoch, loader, model, device, train_mode=False):\n",
    "    mean_loss = 0\n",
    "    for idx,[o,u] in enumerate(tqdm(loader)):#batch_idx, (data, _) in enumerate(tqdm(loader)):\n",
    "        o = o.to(device)\n",
    "        u = u.to(device)\n",
    "        batch_size = o.size()[0]\n",
    "        x = o.transpose(0, 1) #多分転置してるだけ\n",
    "        u = u.transpose(0, 1)\n",
    "        z_prev = torch.tensor(start_pos)#初期姿勢\n",
    "        z_prev = z_prev.repeat(batch_size, 1).to(device)\n",
    "        if train_mode:\n",
    "            mean_loss += model.train({'x': x, 'u':u, 'z_prev': z_prev}).item() * batch_size\n",
    "        else:\n",
    "            mean_loss += model.test({'x': x, 'u':u, 'z_prev': z_prev}).item() * batch_size\n",
    "    mean_loss /= len(loader.dataset)\n",
    "    if train_mode:\n",
    "        print('Epoch: {} Train loss: {:.4f}'.format(epoch, mean_loss))\n",
    "    else:\n",
    "        print('Test loss: {:.4f}'.format(mean_loss))\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_from_latent(batch_size):\n",
    "    x = []\n",
    "    z_prev = torch.zeros(batch_size, z_dim).to(device)\n",
    "    u0 = torch.zeros(batch_size, u_dim).to(device)\n",
    "    for step in range(t_max):\n",
    "        samples = generate_from_prior.sample({'z_prev': z_prev,'u':u0})\n",
    "        x_t = decoder.sample_mean({\"z\": samples[\"z\"]})\n",
    "        z_prev = samples[\"z\"]\n",
    "        x.append(x_t[None, :])\n",
    "    x = torch.cat(x, dim=0).transpose(0, 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/fukku/anaconda3/envs/pixyz/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "100%|██████████| 8/8 [00:05<00:00,  1.63it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 15068978.1440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 15041726.1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.63it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train loss: 15043309.6640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 15048836.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.60it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train loss: 15041985.1120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 15039667.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.62it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Train loss: 15042039.9680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 15047986.3280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.64it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train loss: 15046990.3840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 15045404.4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.62it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Train loss: 15047905.9360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 15052037.4560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.62it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Train loss: 15050351.6880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 15049324.4560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.62it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Train loss: 15049234.0560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 15052191.4320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.61it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Train loss: 15052211.2080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 15046806.3040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.62it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train loss: 15044568.4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 15036417.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.62it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 Train loss: 15034033.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 15027767.8960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.61it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 Train loss: 15024562.0240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 15016727.0720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.63it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 Train loss: 15015111.2480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 15008200.2720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:01<00:03,  1.50it/s]"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "history = {\"train_loss\":[],\"test_loss\":[]}\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = data_loop(epoch, train_loader, dmm, device, train_mode=True)\n",
    "    test_loss = data_loop(epoch, test_loader, dmm, device)\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('test_loss', test_loss, epoch)\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"test_loss\"].append(test_loss)\n",
    "    \n",
    "    sample = plot_image_from_latent(batch_size)[:, None][1,:]\n",
    "    writer.add_image('Image_from_latent', sample, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ylabel('$loss$', fontsize=16)\n",
    "plt.xlabel('$epoch$', fontsize=16)\n",
    "ay=plt.gca()\n",
    "plt.title(\"train_loss\")\n",
    "plt.plot(range(epochs), [i+0.5 for i in history[\"train_loss\"]])\n",
    "plt.show()\n",
    "ay=plt.gca()\n",
    "plt.title(\"test_loss\")\n",
    "plt.plot(range(epochs), [i+0.4 for i in history[\"test_loss\"]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inference_net = rnn*encoder\n",
    "test_o = data[0,:,(1+z_dim+u_dim):(1+z_dim+u_dim+x_dim)]\n",
    "test_o = torch.tensor(test_o).reshape(1,len(test_o),x_dim).to(device)\n",
    "test_u = data[0,:,(1+z_dim):(1+z_dim+u_dim)]\n",
    "test_u = torch.tensor(test_u).reshape(1,len(test_u),u_dim).to(device)\n",
    "z_prev = torch.tensor(start_pos).to(device)\n",
    "infered_result = inference_net.sample({\"x\":test_o,\"z_prev\":z_prev,\"u\":test_u})[\"z\"].to(\"cpu\")\n",
    "infered_result=infered_result.numpy()\n",
    "\n",
    "plt.plot(infered_result[:,:, 0], infered_result[:,:, 1], \"co\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
