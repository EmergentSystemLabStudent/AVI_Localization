{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vae.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"PIOit_8isU2e","colab_type":"text"},"cell_type":"markdown","source":["# Variational autoencoder (using the VAE class)"]},{"metadata":{"id":"SJK6sI9LstfL","colab_type":"code","outputId":"033f0646-c809-41ea-ebe9-ea83bc5244a5","executionInfo":{"status":"ok","timestamp":1548916921765,"user_tz":-540,"elapsed":760,"user":{"displayName":"福井隆士","photoUrl":"","userId":"02045005220596599994"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["%%bash\n","git clone https://github.com/masa-su/pixyz.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["fatal: destination path 'pixyz' already exists and is not an empty directory.\n"],"name":"stderr"}]},{"metadata":{"id":"1Zyt8SIysyY-","colab_type":"code","outputId":"da84f9ed-12b5-4b2f-d8bf-f7610a92c144","executionInfo":{"status":"ok","timestamp":1548916930661,"user_tz":-540,"elapsed":9626,"user":{"displayName":"福井隆士","photoUrl":"","userId":"02045005220596599994"}},"colab":{"base_uri":"https://localhost:8080/","height":274}},"cell_type":"code","source":["# http://pytorch.org/\n","from os.path import exists\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n","accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n","import torch\n","!pip install tensorboardX\n","!pip install -e pixyz --process-dependency-links"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (1.6)\n","Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.6.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.14.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.11.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (40.7.0)\n","\n","Usage:   \n","  pip3 install [options] <requirement specifier> [package-index-options] ...\n","  pip3 install [options] -r <requirements file> [package-index-options] ...\n","  pip3 install [options] [-e] <vcs project url> ...\n","  pip3 install [options] [-e] <local project path> ...\n","  pip3 install [options] <archive url/path> ...\n","\n","no such option: --process-dependency-links\n"],"name":"stdout"}]},{"metadata":{"id":"PbxoCa_3s14g","colab_type":"code","colab":{}},"cell_type":"code","source":["from __future__ import print_function\n","import torch\n","import torch.utils.data\n","from torch import nn, optim\n","from torch.nn import functional as F\n","from torchvision import datasets, transforms\n","from torchvision.utils import save_image\n","from tensorboardX import SummaryWriter\n","\n","from tqdm import tqdm\n","\n","batch_size = 128\n","epochs = 10\n","seed = 1\n","torch.manual_seed(seed)\n","\n","if torch.cuda.is_available():\n","    device = \"cuda\"\n","else:\n","    device = \"cpu\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"p9sJhHFVs8c1","colab_type":"code","colab":{}},"cell_type":"code","source":["root = '../data'\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Lambda(lambd=lambda x: x.view(-1))])\n","kwargs = {'batch_size': batch_size, 'num_workers': 1, 'pin_memory': True}\n","\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST(root=root, train=True, transform=transform, download=True),\n","    shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST(root=root, train=False, transform=transform),\n","    shuffle=False, **kwargs)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9e_6bSYob_EX","colab_type":"code","outputId":"c94937e3-c132-408d-d7b4-f7c6e6db5afa","executionInfo":{"status":"ok","timestamp":1548916931019,"user_tz":-540,"elapsed":9934,"user":{"displayName":"福井隆士","photoUrl":"","userId":"02045005220596599994"}},"colab":{"base_uri":"https://localhost:8080/","height":182}},"cell_type":"code","source":["print(datasets.MNIST(root=root, train=True, transform=transform, download=True))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Dataset MNIST\n","    Number of datapoints: 60000\n","    Split: train\n","    Root Location: ../data\n","    Transforms (if any): Compose(\n","                             ToTensor()\n","                             Lambda()\n","                         )\n","    Target Transforms (if any): None\n"],"name":"stdout"}]},{"metadata":{"id":"DJ571IVtsU2-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":360},"outputId":"1d712eaa-180d-4a9b-ef85-b858ffa43608","executionInfo":{"status":"error","timestamp":1548916931340,"user_tz":-540,"elapsed":10239,"user":{"displayName":"福井隆士","photoUrl":"","userId":"02045005220596599994"}}},"cell_type":"code","source":["from pixyz.distributions import Normal, Bernoulli\n","from pixyz.losses import KullbackLeibler\n","from pixyz.models import VAE"],"execution_count":6,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-9f5d32beb7fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpixyz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBernoulli\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpixyz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKullbackLeibler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpixyz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pixyz.distributions'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"metadata":{"id":"0JsmhqgosU3J","colab_type":"code","colab":{}},"cell_type":"code","source":["x_dim = 784\n","z_dim = 64\n","\n","\n","# inference model q(z|x)\n","class Inference(Normal):\n","    def __init__(self):\n","        super(Inference, self).__init__(cond_var=[\"x\"], var=[\"z\"], name=\"q\")\n","\n","        self.fc1 = nn.Linear(x_dim, 512)\n","        self.fc2 = nn.Linear(512, 512)\n","        self.fc31 = nn.Linear(512, z_dim)\n","        self.fc32 = nn.Linear(512, z_dim)\n","\n","    def forward(self, x):\n","        h = F.relu(self.fc1(x))\n","        h = F.relu(self.fc2(h))\n","        return {\"loc\": self.fc31(h), \"scale\": F.softplus(self.fc32(h))}\n","\n","    \n","# generative model p(x|z)    \n","class Generator(Bernoulli):\n","    def __init__(self):\n","        super(Generator, self).__init__(cond_var=[\"z\"], var=[\"x\"], name=\"p\")\n","\n","        self.fc1 = nn.Linear(z_dim, 512)\n","        self.fc2 = nn.Linear(512, 512)\n","        self.fc3 = nn.Linear(512, x_dim)\n","\n","    def forward(self, z):\n","        h = F.relu(self.fc1(z))\n","        h = F.relu(self.fc2(h))\n","        return {\"probs\": torch.sigmoid(self.fc3(h))}\n","    \n","    \n","# prior model p(z)\n","loc = torch.tensor(0.).to(device)\n","scale = torch.tensor(1.).to(device)\n","prior = Normal(loc=loc, scale=scale, var=[\"z\"], dim=z_dim, name=\"p_prior\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"O4u2hQAUsU3O","colab_type":"code","colab":{}},"cell_type":"code","source":["p = Generator()\n","q = Inference()\n","\n","p.to(device)\n","q.to(device)\n","\n","print(p)\n","print(q)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-NO_tXa9sU3a","colab_type":"code","colab":{}},"cell_type":"code","source":["kl = KullbackLeibler(q, prior)\n","print(kl)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xhb60LHzsU3k","colab_type":"code","colab":{}},"cell_type":"code","source":["model = VAE(q, p, regularizer=kl, optimizer=optim.Adam, optimizer_params={\"lr\":1e-3})\n","print(model)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oxKwSAF5sU3x","colab_type":"code","colab":{}},"cell_type":"code","source":["def train(epoch):\n","    train_loss = 0\n","    for x, _ in tqdm(train_loader):\n","        x = x.to(device)\n","        loss = model.train({\"x\": x})\n","        train_loss += loss\n","        print(x.size())\n"," \n","    train_loss = train_loss * train_loader.batch_size / len(train_loader.dataset)\n","    print('Epoch: {} Train loss: {:.4f}'.format(epoch, train_loss))\n","    return train_loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oZJNBiWfsU4D","colab_type":"code","colab":{}},"cell_type":"code","source":["def test(epoch):\n","    test_loss = 0\n","    for x, _ in test_loader:\n","        x = x.to(device)\n","        loss = model.test({\"x\": x})\n","        test_loss += loss\n","\n","    test_loss = test_loss * test_loader.batch_size / len(test_loader.dataset)\n","    print('Test loss: {:.4f}'.format(test_loss))\n","    return test_loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gFBXlSg-sU4N","colab_type":"code","colab":{}},"cell_type":"code","source":["def plot_reconstrunction(x):\n","    with torch.no_grad():\n","        z = q.sample({\"x\": x}, return_all=False)\n","        recon_batch = p.sample_mean(z).view(-1, 1, 28, 28)\n","    \n","        comparison = torch.cat([x.view(-1, 1, 28, 28), recon_batch]).cpu()\n","        return comparison\n","    \n","def plot_image_from_latent(z_sample):\n","    with torch.no_grad():\n","        sample = p.sample_mean({\"z\": z_sample}).view(-1, 1, 28, 28).cpu()\n","        return sample"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uxV-FAZ3sU4T","colab_type":"code","colab":{}},"cell_type":"code","source":["writer = SummaryWriter()\n","\n","z_sample = 0.5 * torch.randn(64, z_dim).to(device)\n","_x, _ = iter(test_loader).next()\n","_x = _x.to(device)\n","\n","for epoch in range(1, epochs + 1):\n","    train_loss = train(epoch)\n","    test_loss = test(epoch)\n","    \n","    recon = plot_reconstrunction(_x[:8])\n","    sample = plot_image_from_latent(z_sample)\n","\n","    writer.add_scalar('train_loss', train_loss.item(), epoch)\n","    writer.add_scalar('test_loss', test_loss.item(), epoch)      \n","    \n","    writer.add_image('Image_from_latent', sample, epoch)\n","    writer.add_image('Image_reconstrunction', recon, epoch)\n","    \n","writer.close()"],"execution_count":0,"outputs":[]}]}